# Global LLM configuration
[llm]
api_type= 'azure'
model = "gpt-5-2025-08-07"
base_url = "https://fhgenie-api-ipa-genai4aas.openai.azure.com"
api_key = ""
api_version="2024-10-21"
temperature = 1
max_completion_tokens = 4096

[llm.gpt5]
api_type= 'azure'
model = "gpt-5-2025-08-07" #gpt-5-mini-2025-08-07, gpt-5-2025-08-07
base_url = "https://fhgenie-api-ipa-genai4aas.openai.azure.com"
api_key = ""
api_version="2024-10-21"
temperature = 1
max_completion_tokens = 4096

[llm.gpt5mini_openai] #OPENAI:
api_type= 'Openai'
model = "gpt-5-mini" #"gpt-4o-mini"
base_url = "https://api.openai.com/v1/chat/completions"
api_key = ""
temperature = 1
max_completion_tokens = 4096
max_tokens = 4096

[llm.deepseek]
api_type= 'Openai'
model = "deepseek-reasoner"
base_url = "https://api.deepseek.com"
api_key = ""
temperature = 0
max_tokens = 4096

[llm.ollama] #OLLAMA:
api_type = 'ollama'
model = "llama3.2"
base_url = "http://localhost:11434/v1"
api_key = "ollama"
max_tokens = 4096
temperature = 0.0

[llm.gemini]
api_type = 'google'
model = "gemini-3-flash-preview"
base_url = "https://generativelanguage.googleapis.com"  # dummy
api_key = ""
api_version = "v1"  # dummy
max_tokens = 8192
temperature = 0.7
